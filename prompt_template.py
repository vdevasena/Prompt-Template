# -*- coding: utf-8 -*-
"""Prompt Template.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11AJcn22PvyP3U1Vae8BB-uzDMy2Pv7Lb
"""

!pip install openai

from openai import OpenAI
import openai
import os
#from kaggle_secrets import UserSecretsClient

#user_secrets = UserSecretsClient()
#openai.api_key = user_secrets.get_secret("openai_api")
client = OpenAI(
    # This is the default and can be omitted
    api_key="api-key",
    )

llm_model = "gpt-3.5-turbo"

def get_completion(prompt,
                   llm_model=llm_model,
                   temperature=0,
                   max_tokens=500):

    messages = [{"role": "user", "content": prompt}]
    response = client.chat.completions.create(
        model=llm_model,
        messages=messages,
        temperature=temperature,
        max_tokens=max_tokens,
    )
    return response.choices[0].message.content

customer_email = """
Arrr, I be fuming that me blender lid \
flew off and splattered me kitchen walls \
with smoothie! And to make matters worse,\
the warranty don't cover the cost of \
cleaning up me kitchen. I need yer help \
right now, matey!
"""

style = """American English \
in a calm and respectful tone
"""

prompt = f"""Translate the text \
that is delimited by triple backticks
into a style that is {style}.
text: ```{customer_email}```
"""

print(prompt)

response = get_completion(prompt)
response

!pip install langchain-community

from langchain_community.chat_models import ChatOpenAI

# To control the randomness and creativity of the generated
# text by an LLM, use temperature = 0.0

chat = ChatOpenAI(temperature=0.0, model=llm_model, openai_api_key="api-key")

template_string = """Translate the text \
that is delimited by triple backticks \
into a style that is {style}. \
text: ```{text}```
"""

from langchain_core.prompts import ChatPromptTemplate

prompt_template = ChatPromptTemplate.from_template(template_string)

prompt_template.messages[0].prompt

prompt_template.messages[0].prompt.input_variables

customer_style = """American English \
in a calm and respectful tone
"""

customer_email = """
Arrr, I be fuming that me blender lid \
flew off and splattered me kitchen walls \
with smoothie! And to make matters worse, \
the warranty don't cover the cost of \
cleaning up me kitchen. I need yer help \
right now, matey!
"""

customer_messages = prompt_template.format_messages(
                    style=customer_style,
                    text=customer_email)

print(type(customer_messages))
print(type(customer_messages[0]))

# Call the LLM to translate to the style of the customer message
customer_response = chat(customer_messages)

print(customer_response.content)

service_style_pirate = """\
a polite tone \
that speaks in English Pirate\
"""

service_reply = """Hey there customer, \
the warranty does not cover \
cleaning expenses for your kitchen \
because it's your fault that \
you misused your blender \
by forgetting to put the lid on before \
starting the blender. \
Tough luck! See ya!
"""

service_messages = prompt_template.format_messages(
    style=service_style_pirate,
    text=service_reply)

print(service_messages[0].content)

service_response = chat(service_messages)
print(service_response.content)